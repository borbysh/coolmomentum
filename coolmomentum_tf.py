"""Coolmomentum for TensorFlow."""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from tensorflow.python.framework import ops
from tensorflow.python.keras import backend_config
from tensorflow.python.keras.optimizer_v2 import optimizer_v2
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import control_flow_ops
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import state_ops
from tensorflow.python.training import training_ops
from tensorflow.python.util.tf_export import keras_export
import math


class Coolmomentum(optimizer_v2.OptimizerV2):
  """Optimizer that implements the Coolmomentum algorithm."""

  def __init__(self,
               learning_rate=0.01,
               rho_0=0.99,
               alpha=0.99997,
               name='Coolmomentum',
               **kwargs):
    r"""Construct a new Coolmomentum optimizer.
    
    
    Args:
      learning_rate: A Tensor or a floating point value.  The squared timestep "dt^2".
      rho_0: A float value or a constant float tensor. The initial value
        for the momentum coefficient "rho_0". Default rho_0=0.99.
      alpha: A float value or a constant float tensor. "Alpha" is a cooling rate,
        being a Simulated Annealing parameter. Calculated as alpha=(1-rho_0)^(1/S), where S is a total number of iterations. 
        If alpha=1 the momentum coefficient is constant and Simulated Annealing is not applied. Then the optimizer behaves like simple Momentum.
      name: Optional name for the operations created when applying gradients.
        Defaults to "Coolmomentum".
      **kwargs: keyword arguments. Allowed to be {`clipnorm`, `clipvalue`, `lr`,
        `decay`}. `clipnorm` is clip gradients by norm; `clipvalue` is clip
        gradients by value, `decay` is included for backward compatibility to
        allow time inverse decay of learning rate. `lr` is included for backward
        compatibility, recommended to use `learning_rate` instead.
    @compatibility(eager)
    When eager execution is enabled, `learning_rate`, `rho_0` and `alpha`
    can each be a callable that takes no arguments and
    returns the actual value to use. This can be useful for changing these
    values across different invocations of optimizer functions.
    @end_compatibility
    """

    super(Coolmomentum, self).__init__(name, **kwargs)
    self._set_hyper('learning_rate', kwargs.get('lr', learning_rate))
    self._set_hyper('decay', self._initial_decay)
    self._set_hyper('rho_0', rho_0)
    self._set_hyper('alpha', alpha)
    

  def _create_slots(self, var_list):
    # Create a slot for the parameter update.
    
    for var in var_list:
      self.add_slot(var, 'x')
    

  def _prepare_local(self, var_device, var_dtype, apply_state):
    super(Coolmomentum, self)._prepare_local(var_device, var_dtype, apply_state)

    local_step = math_ops.cast(self.iterations, var_dtype)
    rho_0_t = array_ops.identity(self._get_hyper('rho_0', var_dtype))
    alpha_t = array_ops.identity(self._get_hyper('alpha', var_dtype))
    alpha_power = math_ops.pow(alpha_t, (local_step))
    lr = apply_state[(var_device, var_dtype)]['lr_t'] 
    apply_state[(var_device, var_dtype)].update(dict(
        lr=lr,
        rho_0_t=rho_0_t,
        alpha_t=alpha_t,
        alpha_power=alpha_power 
    ))

  def set_weights(self, weights):
    params = self.weights
    # If the weights are generated by Keras V1 optimizer, it includes vhats
    # even without amsgrad, i.e, V1 optimizer has 3x + 1 variables, while V2
    # optimizer has 2x + 1 variables. Filter vhats out for compatibility.
    num_vars = int((len(params) - 1) / 2)
    if len(weights) == 3 * num_vars + 1:
      weights = weights[:len(params)]
    super(Coolmomentum, self).set_weights(weights)

  def _resource_apply_dense(self, grad, var, apply_state=None):
    var_device, var_dtype = var.device, var.dtype.base_dtype
    coefficients = ((apply_state or {}).get((var_device, var_dtype))
                    or self._fallback_apply_state(var_device, var_dtype))
   
    rho = 1 - ((1-coefficients['rho_0_t'])/coefficients['alpha_power'])
    rho=math_ops.maximum(rho,0)
#    print(rho)
    
    x = self.get_slot(var, 'x')
    x_update = grad * coefficients['lr'] * ((1 + rho) / 2)
    x_t = state_ops.assign(x, x * rho,
                           use_locking=self._use_locking)
    with ops.control_dependencies([x_t]):
      x_t = state_ops.assign_add(x, x_update)


    var_update = state_ops.assign_sub(
        var, x_t,
        use_locking=self._use_locking)
    return control_flow_ops.group(*[var_update,  x_t])


  def _resource_apply_sparse(self, grad, var, indices, apply_state=None):
    var_device, var_dtype = var.device, var.dtype.base_dtype
    coefficients = ((apply_state or {}).get((var_device, var_dtype))
                    or self._fallback_apply_state(var_device, var_dtype))

    rho = 1 - ((1-coefficients['rho_0_t'])/coefficients['alpha_power'])
    rho=math_ops.maximum(rho,0)
#    print(rho)

    x = self.get_slot(var, 'x')
    x_update = grad * coefficients['lr'] * ((1 + rho) / 2)
    x_t = state_ops.assign(x, x * rho,
                           use_locking=self._use_locking)
    with ops.control_dependencies([x_t]):
      x_t = self._resource_scatter_add(x, indices, x_update)

    
    var_update = state_ops.assign_sub(
        var, x_t,
        use_locking=self._use_locking)
    return control_flow_ops.group(*[var_update, x_t])

  def get_config(self):
    config = super(Coolmomentum, self).get_config()
    config.update({
        'learning_rate': self._serialize_hyperparameter('learning_rate'),
        'decay': self._serialize_hyperparameter('decay'),
        'rho_0': self._serialize_hyperparameter('rho_0'),
        'alpha': self._serialize_hyperparameter('alpha'),
    })
    return config
